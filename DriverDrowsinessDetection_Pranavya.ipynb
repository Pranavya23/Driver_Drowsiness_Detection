{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f2ca061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "from imutils import face_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc32498c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "    exit()\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Cannot read frame.\")\n",
    "        break\n",
    "    cv2.imshow('Video Capture', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23967fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detector = dlib.get_frontal_face_detector()\n",
    "landmark_predictor = dlib.shape_predictor(\"C:\\\\Users\\\\rakul\\\\Downloads\\\\archive\\\\shape_predictor_68_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a7c847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "    exit()\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Error: Cannot read frame.\")\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale for faster processing\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the grayscale frame\n",
    "    faces = face_detector(gray)\n",
    "\n",
    "    # Iterate over detected faces\n",
    "    for face in faces:\n",
    "        # Determine facial landmarks\n",
    "        landmarks = landmark_predictor(gray, face)\n",
    "        landmarks = face_utils.shape_to_np(landmarks)\n",
    "\n",
    "        # Draw the facial landmarks on the frame\n",
    "        for (x, y) in landmarks:\n",
    "            cv2.circle(frame,(x,y),1,(255, 255, 255),-1)\n",
    "\n",
    "    # Display the frame with landmarks\n",
    "    cv2.imshow('Facial Landmarks', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ec344af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import playsound\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# Function to play alarm sound\n",
    "def play_alarm_sound():\n",
    "    playsound.playsound(\"mixkit-classic-alarm-995.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "645c04eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the Euclidean distance between two points\n",
    "def compute_distance(pointA, pointB):\n",
    "    distance = np.linalg.norm(pointA - pointB)\n",
    "    return distance\n",
    "\n",
    "# Function to calculate the Eye Aspect Ratio (EAR)\n",
    "def calculate_ear(eye_points):\n",
    "    vertical_distance = compute_distance(eye_points[1], eye_points[5]) + compute_distance(eye_points[2], eye_points[4])\n",
    "    horizontal_distance = compute_distance(eye_points[0], eye_points[3])\n",
    "    eye_aspect_ratio = vertical_distance / (2.0 * horizontal_distance)\n",
    "    return eye_aspect_ratio\n",
    "\n",
    "# Function to determine the blink state based on EAR and normal EAR\n",
    "def get_blink_state(ear, normal_ear):\n",
    "    if normal_ear*0.8 <= ear:\n",
    "        return 2  # Eyes open if 80% of the eye or more is open\n",
    "    elif ear >= normal_ear * 0.5:\n",
    "        return 1  # Eyes drowsy\n",
    "    else:\n",
    "        return 0  # Eyes closed if less than 50% of eye is open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ceaa70de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capturing initial frames to calculate normal EAR. Please keep your eyes open.\n",
      "Normal EAR calculated: 0.3540697086690955\n"
     ]
    }
   ],
   "source": [
    "# Initialize counters and status variables\n",
    "sleep_counter = 0\n",
    "drowsy_counter = 0\n",
    "active_counter = 0\n",
    "alert_status = \"\"\n",
    "status_color = (0, 0, 0)\n",
    "alarm_play_count = 0\n",
    "frame_count = 0\n",
    "normal_ear = 0\n",
    "\n",
    "\n",
    "# Initialize video capture from the default camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Unable to open camera\")\n",
    "    exit()\n",
    "    \n",
    "# Capture first 20 frames to calculate the normal EAR\n",
    "print(\"Capturing initial frames to calculate normal EAR. Please keep your eyes open.\")\n",
    "time.sleep(2)  # Give the driver some time to prepare\n",
    "\n",
    "while frame_count < 20:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"End of video stream\")\n",
    "        break\n",
    "\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    detected_faces = face_detector(gray_frame)\n",
    "\n",
    "    for face in detected_faces:\n",
    "        landmarks = landmark_predictor(gray_frame, face)\n",
    "        landmarks = face_utils.shape_to_np(landmarks)\n",
    "\n",
    "        left_eye_ear = calculate_ear(landmarks[36:42])\n",
    "        right_eye_ear = calculate_ear(landmarks[42:48])\n",
    "\n",
    "        normal_ear += (left_eye_ear + right_eye_ear) / 2.0\n",
    "        frame_count += 1\n",
    "\n",
    "normal_ear /= 20.0\n",
    "print(f\"Normal EAR calculated: {normal_ear}\")\n",
    "\n",
    "# Main loop to process video frames\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"End of video stream\")\n",
    "        break\n",
    "\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    detected_faces = face_detector(gray_frame)\n",
    "\n",
    "    for face in detected_faces:\n",
    "        landmarks = landmark_predictor(gray_frame, face)\n",
    "        landmarks = face_utils.shape_to_np(landmarks)\n",
    "\n",
    "        left_eye_ear = calculate_ear(landmarks[36:42])\n",
    "        right_eye_ear = calculate_ear(landmarks[42:48])\n",
    "\n",
    "        left_eye_blink = get_blink_state(left_eye_ear, normal_ear)\n",
    "        right_eye_blink = get_blink_state(right_eye_ear, normal_ear)\n",
    "\n",
    "        if left_eye_blink == 0 or right_eye_blink == 0:\n",
    "            sleep_counter += 1\n",
    "            drowsy_counter = 0\n",
    "            active_counter = 0\n",
    "            if sleep_counter > 6:\n",
    "                alert_status = \"Sleeping!!!\"\n",
    "                status_color = (46, 29, 255)\n",
    "        elif left_eye_blink == 1 or right_eye_blink == 1:\n",
    "            sleep_counter = 0\n",
    "            active_counter = 0\n",
    "            drowsy_counter += 1\n",
    "            if drowsy_counter > 6:\n",
    "                alert_status = \"Drowsy!!\"\n",
    "                status_color = (15, 193, 220)\n",
    "        else:\n",
    "            drowsy_counter = 0\n",
    "            sleep_counter = 0\n",
    "            active_counter += 1\n",
    "            if active_counter > 6:\n",
    "                alert_status = \"Active\"\n",
    "                status_color = (86, 171, 22)\n",
    "                alarm_play_count = 0  # Reset alarm counter when active\n",
    "\n",
    "        # Display the alert status on the frame\n",
    "        cv2.putText(frame, alert_status, (100, 100), cv2.FONT_HERSHEY_SIMPLEX, 1.2, status_color, 3)\n",
    "        \n",
    "        # Play alarm sound if the user is sleepy or drowsy and the alarm hasn't played 30 times yet\n",
    "        if (alert_status == \"Sleeping!!!\" or alert_status == \"Drowsy!!\") and alarm_play_count < 30:\n",
    "            thread = threading.Thread(target=play_alarm_sound)\n",
    "            thread.daemon = True\n",
    "            thread.start()\n",
    "            alarm_play_count += 1\n",
    "\n",
    "        # Draw facial landmarks on the frame\n",
    "        for (x, y) in landmarks:\n",
    "            cv2.circle(frame, (x, y), 2, (255, 255, 255), -1)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Driver Alert System\", frame)\n",
    "\n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b629f888",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
